{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN056aq1nw60Jz5wNy2awwy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raunakaga2004/HOML-ch2/blob/main/TrainTestSplit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yaPmtYX-B8T6"
      },
      "outputs": [],
      "source": [
        "# same as train_test_split by scikit learn\n",
        "\n",
        "# Shuffles the data randomly and split according to test_ratio and return train and test data split.\n",
        "\n",
        "import numpy as np;\n",
        "\n",
        "def shuffle_and_split_data(data, test_ratio, seed = 42) :\n",
        "\n",
        "  np.random.seed(seed); # set the seed, default is 42\n",
        "\n",
        "  # Shuffle the indices of rows in data\n",
        "  shuffled_indices = np.random.permutation(np.array(data.index)) # np.random.permutations shuffles the array elements\n",
        "\n",
        "  # Number of rows as test case on the basis of test_ratio\n",
        "  test_rows = int(len(data) * test_ratio) #len(data) means number of rows in data\n",
        "\n",
        "  # Get the test_rows amount of top shuffled indices rows\n",
        "  test_indices = shuffled_indices[:test_rows];\n",
        "\n",
        "  # Get the train data rows\n",
        "  train_indices = shuffled_indices[test_rows:];\n",
        "\n",
        "  # return train and test data\n",
        "  return data.iloc[train_indices], data.iloc[test_indices];\n",
        "\n",
        "\n",
        "# Limitations :\n",
        "  # Every time it will generate different test set and train set which will allow machine learning model to see whole dataset which is not good because we want to separate some amount of data to validate the model.\n",
        "\n",
        "  # => for that we used seed above\n",
        "\n",
        "# Solutions :\n",
        "  # Save the test set in first run then load it in subsequent run\n",
        "  # Set random number generator's seed\n",
        "\n",
        "# Limitations of Solutions :\n",
        "  # they will generate different sets if the dataset is updated\n",
        "\n",
        "# Solution :\n",
        "  # to have stable split among train and test set we can use hash of row to identify whether it will go in train or test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hash based splitting of train and test set of dataset\n",
        "\n",
        "import numpy as np;\n",
        "from zlib import crc32; # zlib is the library used for data compression. crc32 is a type of checksum algorithm, crc32 calculates a 32-bit checksum value based on the input data.\n",
        "\n",
        "def is_id_in_test_set( identifier, test_ratio) : # identifier is the unique element on which whole row will be decided that whether it will go in test or train set on basis of test_ratio\n",
        "  return crc32(np.int64(identifier)) < test_ratio * 2 ** 32; # returns true or false\n",
        "\n",
        "def split_data_with_hash (data, test_ratio, id_column) : # id_column is the column which is or which can be a primary key i.e. which can define uniqueness of row\n",
        "  ids = data[id_column]\n",
        "  in_test_set = ids.apply(lambda id_ : is_id_in_test_set(id_, test_ratio))\n",
        "\n",
        "  return data.loc[~in_test_set], data.loc[in_test_set] # not true means in train set and true means in test set\n",
        "\n",
        "# Benefits :\n",
        "  # this will give the same rows in test set everytime whether new data is added or not"
      ],
      "metadata": {
        "id": "EM9G1Qp8F7_S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other type is StratfiedShuffleSplit of sklearn library which divides data into bins and then extract the test_ratio percentage from each bin randomly\n",
        "\n",
        "# Benefits :\n",
        "  # It is beneficial because it doesn't change the distribution of data\n",
        "  # and it represent the population data on the basis of that column of data"
      ],
      "metadata": {
        "id": "Dpen8Q7LoACk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}